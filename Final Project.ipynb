{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Kindle Store Review Analysis\n",
    "\n",
    "**Table of Contents:**  \n",
    "1. [Background](#background)  \n",
    "2. [Data and Methods](#data)  \n",
    "    2.1 [Modeling Methodology](#mmethod)  \n",
    "3. [Models and Classifications](#models)  \n",
    "    3.1 [Multiclass](#multiclass)  \n",
    "    3.2 [Best vs Rest](#best)  \n",
    "    3.3 [Worst vs Rest](#worst)  \n",
    "    3.4 [Top Half vs Bottom Half](#fifty)  \n",
    "    3.5 [Linear Regression on Sales Rank](#linreg)\n",
    "4. [Results and Analysis](#res)  \n",
    "5. [Conclusions](#concl)  \n",
    "6. [Citations](#cit)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "<a id=\"background\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon reviews can be a means of measuring the impact of a book in the wider market. While for academic works, the number of citations is often used for measurement of book impact [[1]](#cit1), citation counts are not every well correlated with reader review counts on other sites [[2]](#cit2). Additionally, these metrics are unavailable for non-academic books as well as for books that aim to provide primarily an educational or cultural impact [[3]](#cit3). It is possible, however, to utilize reader reviews to measure book impact of both academic books [[4]](#cit4) and non-academic books. While, for the most part, reviews tend to be mostly positive, reviews do have an effect on the sales of the book, and therefore also affect cultural impact [[5]](#cit5).  \n",
    "\n",
    "Given that reviews can have an effect on the sales of a book, each review would therefore have an impact on the Amazon sales rank. If a single Amazon review can predict the sales rank of a Kindle book being reviewed, it should be possible to determine the potential success of a book based on a small sample of readers before the book is even sold, and thus its potential cultural impact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data and Methods\n",
    "<a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ascertain whether or not a single Amazon review can predict the quality of the Kindle book being reviewed, two datasets were used. Both were acquired through Amazon review data from 2018 by Jianmo Ni [[6]](#cit6). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset is a 5-core subset of Amazon Kindle review data, in which all users and items have at least 5 reviews. This dataset consisted of reviews for Kindle books, and included information such as the ASIN, the review text, and other information about each review. There are a total of 2,222,983 reviews in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 3, 2014</td>\n",
       "      <td>A2LSKD2H9U8N0J</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>sandra sue marsolek</td>\n",
       "      <td>pretty good story, a little exaggerated, but I...</td>\n",
       "      <td>pretty good story</td>\n",
       "      <td>1404345600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>05 26, 2014</td>\n",
       "      <td>A2QP13XTJND1QS</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Tpl</td>\n",
       "      <td>If you've read other max brand westerns, you k...</td>\n",
       "      <td>A very good book</td>\n",
       "      <td>1401062400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 16, 2016</td>\n",
       "      <td>A8WQ7MAG3HFOZ</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Alverne F. Anderson</td>\n",
       "      <td>Love Max, always a fun twist</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1473984000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 3, 2016</td>\n",
       "      <td>A1E0MODSRYP7O</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>As usual for him, a good book</td>\n",
       "      <td>a good</td>\n",
       "      <td>1456963200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 10, 2015</td>\n",
       "      <td>AYUTCGVSM1H7T</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>DEHS - EddyRapcon</td>\n",
       "      <td>MB is one of the original western writers and ...</td>\n",
       "      <td>A Western</td>\n",
       "      <td>1441843200</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      4.0      True   07 3, 2014  A2LSKD2H9U8N0J  B000FA5KK0   \n",
       "1      5.0      True  05 26, 2014  A2QP13XTJND1QS  B000FA5KK0   \n",
       "2      5.0      True  09 16, 2016   A8WQ7MAG3HFOZ  B000FA5KK0   \n",
       "3      5.0      True   03 3, 2016   A1E0MODSRYP7O  B000FA5KK0   \n",
       "4      5.0      True  09 10, 2015   AYUTCGVSM1H7T  B000FA5KK0   \n",
       "\n",
       "                            style         reviewerName  \\\n",
       "0  {'Format:': ' Kindle Edition'}  sandra sue marsolek   \n",
       "1  {'Format:': ' Kindle Edition'}                  Tpl   \n",
       "2  {'Format:': ' Kindle Edition'}  Alverne F. Anderson   \n",
       "3  {'Format:': ' Kindle Edition'}                 Jeff   \n",
       "4  {'Format:': ' Kindle Edition'}    DEHS - EddyRapcon   \n",
       "\n",
       "                                          reviewText            summary  \\\n",
       "0  pretty good story, a little exaggerated, but I...  pretty good story   \n",
       "1  If you've read other max brand westerns, you k...   A very good book   \n",
       "2                       Love Max, always a fun twist         Five Stars   \n",
       "3                      As usual for him, a good book             a good   \n",
       "4  MB is one of the original western writers and ...          A Western   \n",
       "\n",
       "   unixReviewTime vote image  \n",
       "0      1404345600  NaN   NaN  \n",
       "1      1401062400  NaN   NaN  \n",
       "2      1473984000  NaN   NaN  \n",
       "3      1456963200  NaN   NaN  \n",
       "4      1441843200    2   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = getDF('Kindle_Store_5.json.gz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>pretty good story, a little exaggerated, but I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>If you've read other max brand westerns, you k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>Love Max, always a fun twist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>As usual for him, a good book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>MB is one of the original western writers and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified        asin  \\\n",
       "0      4.0         1  B000FA5KK0   \n",
       "1      5.0         1  B000FA5KK0   \n",
       "2      5.0         1  B000FA5KK0   \n",
       "3      5.0         1  B000FA5KK0   \n",
       "4      5.0         1  B000FA5KK0   \n",
       "\n",
       "                                          reviewText  \n",
       "0  pretty good story, a little exaggerated, but I...  \n",
       "1  If you've read other max brand westerns, you k...  \n",
       "2                       Love Max, always a fun twist  \n",
       "3                      As usual for him, a good book  \n",
       "4  MB is one of the original western writers and ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['reviewTime', 'style', 'image', 'reviewerID',\n",
    "                 'reviewerName', 'unixReviewTime', 'summary', 'vote'], inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "df = df.replace({True:1,False:0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df.groupby('asin').mean()['overall']\n",
    "s2 = df.groupby('asin').count()['reviewText']\n",
    "classes = pd.concat([s1, s2], axis=1)\n",
    "classes = classes.rename(columns={\"overall\": \"average rating\", \"reviewText\": \"numReviews\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second dataset is a Kindle Store metadata dataset, consisting of metadata on each item sold, such as the ASIN and the Amazon sales rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin\n",
       "0143065971    1,857,911 Paid in Kindle Store (\n",
       "1423600150      682,905 Paid in Kindle Store (\n",
       "B000FA5KKA    1,716,849 Paid in Kindle Store (\n",
       "B000FA5M3K    1,683,973 Paid in Kindle Store (\n",
       "B000FA5KJQ    3,394,136 Paid in Kindle Store (\n",
       "Name: rank, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = getDF('meta_Kindle_Store.json.gz')\n",
    "meta = meta.set_index('asin')\n",
    "meta = meta['rank']\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = classes.join(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumRank(rankstr):\n",
    "    string = str(rankstr).split()[0].replace(\",\",\"\")\n",
    "    if string != 'nan' and string != '[]':\n",
    "        return int(string)\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average rating</th>\n",
       "      <th>numReviews</th>\n",
       "      <th>numRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B000FA5KK0</th>\n",
       "      <td>4.615385</td>\n",
       "      <td>13</td>\n",
       "      <td>5062792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FA5PV4</th>\n",
       "      <td>4.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>549700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FA64PK</th>\n",
       "      <td>4.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>350999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FA64QO</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>139367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FA65EK</th>\n",
       "      <td>2.571429</td>\n",
       "      <td>7</td>\n",
       "      <td>887049.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            average rating  numReviews    numRank\n",
       "asin                                             \n",
       "B000FA5KK0        4.615385          13  5062792.0\n",
       "B000FA5PV4        4.166667           6   549700.0\n",
       "B000FA64PK        4.125000           8   350999.0\n",
       "B000FA64QO        3.666667           9   139367.0\n",
       "B000FA65EK        2.571429           7   887049.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes['numRank'] = classes['rank'].apply(getNumRank)\n",
    "classes = classes.drop(columns=['rank'])\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average rating</th>\n",
       "      <th>numReviews</th>\n",
       "      <th>numRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>98824.000000</td>\n",
       "      <td>98824.000000</td>\n",
       "      <td>9.862700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.370076</td>\n",
       "      <td>22.494364</td>\n",
       "      <td>8.633919e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.453519</td>\n",
       "      <td>34.394862</td>\n",
       "      <td>7.567172e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.142857</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.154150e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.444444</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.912710e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.698238</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.190253e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2218.000000</td>\n",
       "      <td>5.213707e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       average rating    numReviews       numRank\n",
       "count    98824.000000  98824.000000  9.862700e+04\n",
       "mean         4.370076     22.494364  8.633919e+05\n",
       "std          0.453519     34.394862  7.567172e+05\n",
       "min          1.000000      1.000000  6.000000e+00\n",
       "25%          4.142857      7.000000  3.154150e+05\n",
       "50%          4.444444     12.000000  6.912710e+05\n",
       "75%          4.698238     24.000000  1.190253e+06\n",
       "max          5.000000   2218.000000  5.213707e+06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the initial featurization, each quartile of data based on sales rank is given a separate class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315415.0 691271.0 1190253.0\n"
     ]
    }
   ],
   "source": [
    "qBest = classes[\"numRank\"].quantile(0.25)\n",
    "q50 = classes[\"numRank\"].quantile(0.5)\n",
    "qWorst = classes[\"numRank\"].quantile(0.75)\n",
    "print(qBest, q50, qWorst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defClass(x):\n",
    "    if x <= qBest:\n",
    "        return 0\n",
    "    elif qBest < x <= q50:\n",
    "        return 1\n",
    "    elif q50 < x <= qWorst:\n",
    "        return 2\n",
    "    elif qWorst < x:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average rating</th>\n",
       "      <th>numReviews</th>\n",
       "      <th>numRank</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B000FA5KK0</th>\n",
       "      <td>4.615385</td>\n",
       "      <td>13</td>\n",
       "      <td>5062792.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FA5PV4</th>\n",
       "      <td>4.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>549700.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FA64PK</th>\n",
       "      <td>4.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>350999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FA64QO</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>139367.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FA65EK</th>\n",
       "      <td>2.571429</td>\n",
       "      <td>7</td>\n",
       "      <td>887049.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            average rating  numReviews    numRank  class\n",
       "asin                                                    \n",
       "B000FA5KK0        4.615385          13  5062792.0    3.0\n",
       "B000FA5PV4        4.166667           6   549700.0    1.0\n",
       "B000FA64PK        4.125000           8   350999.0    1.0\n",
       "B000FA64QO        3.666667           9   139367.0    0.0\n",
       "B000FA65EK        2.571429           7   887049.0    2.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes['class'] = classes['numRank'].apply(defClass)\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>class</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>pretty good story, a little exaggerated, but I...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5062792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>If you've read other max brand westerns, you k...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5062792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>Love Max, always a fun twist</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5062792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>As usual for him, a good book</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5062792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>B000FA5KK0</td>\n",
       "      <td>MB is one of the original western writers and ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5062792.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified        asin  \\\n",
       "0      4.0         1  B000FA5KK0   \n",
       "1      5.0         1  B000FA5KK0   \n",
       "2      5.0         1  B000FA5KK0   \n",
       "3      5.0         1  B000FA5KK0   \n",
       "4      5.0         1  B000FA5KK0   \n",
       "\n",
       "                                          reviewText  class       rank  \n",
       "0  pretty good story, a little exaggerated, but I...    3.0  5062792.0  \n",
       "1  If you've read other max brand westerns, you k...    3.0  5062792.0  \n",
       "2                       Love Max, always a fun twist    3.0  5062792.0  \n",
       "3                      As usual for him, a good book    3.0  5062792.0  \n",
       "4  MB is one of the original western writers and ...    3.0  5062792.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getClass(asin):\n",
    "    return classes.loc[asin, 'class']\n",
    "\n",
    "def getRank(asin):\n",
    "    return classes.loc[asin, 'numRank']\n",
    "\n",
    "df['class'] = df['asin'].apply(getClass)\n",
    "df['rank'] = df['asin'].apply(getRank)\n",
    "df.dropna(subset=['class', 'rank'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df['class'].to_numpy()\n",
    "r = df['rank'].to_numpy()\n",
    "t = df['reviewText'].apply(lambda x: str(x)).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is shuffled and then split into testing, training, and validation classes. This was done by first splitting the data into 67% training and 33% testing, and then splitting the training into 67% training and 33% validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,c,r = shuffle(t,c,r)\n",
    "X_train, X_test, y_train, y_test, yreg_train, yreg_test = train_test_split(t, c, r, test_size=0.33)\n",
    "X_train, X_valid, y_train, y_valid, yreg_train, yreg_valid = train_test_split(X_train, y_train, yreg_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each review, the review text was vectorized using a weighted vectorizer, resulting in a sparse matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vect.fit_transform(X_train)\n",
    "X_valid = vect.transform(X_valid)\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Modeling Methodology\n",
    "<a id=\"mmethod\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models used for predictions are the perceptron, logistic regression, and linear SVC models from the Python sklearn library. These were chosen due to their speed and interpretability. The validation data is used for the logistic regression and linear SVC models in order to find the C value that would produce the best fit for regularization. All models are then scored using the F1 score on testing data. Additionally, the highest and lowest weighted words for each classifier are found for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscores = [] #f1 scores for perceptrons\n",
    "lscores = [] #f1 scores for logistic regressors\n",
    "sscores = [] #f1 scores for linear svms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLowHigh(coef):\n",
    "    sorted_weights = np.argsort(coef)\n",
    "    lo = []\n",
    "    hi = []\n",
    "    for i in range(30): \n",
    "        lo.append(features[sorted_weights[0,i]])\n",
    "    for i in range(30): \n",
    "        hi.append(features[sorted_weights[0,len(sorted_weights[0])-i-1]])\n",
    "    return lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(X_train, y_train, X_valid, y_valid, classifier):\n",
    "    scores = []\n",
    "    def createModel(i, classifier):\n",
    "        if classifier == \"log\":\n",
    "            return LogisticRegression(C=i)\n",
    "        elif classifier == \"svm\":\n",
    "            return LinearSVC(C=i)\n",
    "        else:\n",
    "            print(\"Use either log or svm\")\n",
    "            return\n",
    "    for i in [1, 10, 100, 1000]:\n",
    "        model = createModel(i, classifier)\n",
    "        model.fit(X_train, y_train)\n",
    "        f1 = f1_score(y_valid, model.predict(X_valid), average='weighted')\n",
    "        scores.append((f1, i))\n",
    "    return scores\n",
    "\n",
    "def getBestC(scores):\n",
    "    return max(scores, key=lambda s: s[0])[1]\n",
    "\n",
    "def appendScore(f1, classifier):\n",
    "    if classifier == \"log\":\n",
    "        lscores.append(f1)\n",
    "    elif classifier == \"svm\":\n",
    "        sscores.append(f1)\n",
    "    elif classifier == \"per\":\n",
    "        pscores.append(f1)\n",
    "    else:\n",
    "        print(\"Must be log, svm or per\")\n",
    "\n",
    "def testModel(classifier, X_train, y_train, X_test, y_test, i=None):\n",
    "    def createModel(classifier, i):\n",
    "        if classifier == \"log\":\n",
    "            return LogisticRegression(C=i)\n",
    "        elif classifier == \"svm\":\n",
    "            return LinearSVC(C=i)\n",
    "        elif classifier == \"per\":\n",
    "            return Perceptron()\n",
    "        else:\n",
    "            print(\"Must be log, svm or per\")\n",
    "            return\n",
    "    model = createModel(classifier, i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    wlo, whi = getLowHigh(model.coef_)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    appendScore(f1, classifier)\n",
    "    return f1, wlo, whi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Models and Classifications\n",
    "<a id=\"models\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Models\n",
    "<a id=\"multiclass\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, the reviews were split into four classes based on quartiles for multiclass modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lows = []\n",
    "multi_his = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, wlo, whi = testModel(\"per\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4376293971429222"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_lows.append(wlo)\n",
    "multi_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.4279718911012983, 1),\n",
       " (0.4370485228787541, 10),\n",
       " (0.43006479387120544, 100),\n",
       " (0.43119120439494196, 1000)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validscores = getScores(X_train, y_train, X_valid, y_valid, \"log\")\n",
    "validscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "i = getBestC(validscores)\n",
    "f1, wlo, whi = testModel(\"log\", X_train, y_train, X_test, y_test, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43784356907683936"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_lows.append(wlo)\n",
    "multi_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.4913556866872545, 1),\n",
       " (0.49448746760149587, 10),\n",
       " (0.48398322502064495, 100),\n",
       " (0.4581862107683906, 1000)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validscores = getScores(X_train, y_train, X_valid, y_valid, \"svm\")\n",
    "validscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = getBestC(validscores)\n",
    "f1, wlo, whi = testModel(\"svm\", X_train, y_train, X_test, y_test, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49640295814324614"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_lows.append(wlo)\n",
    "multi_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best vs Rest\n",
    "<a id=\"best\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, the reviews were split into two classes. The first class is those reviews for books with an Amazon sales rank in the lowest quartile, i.e. the most successful books, and the second class is all of the other books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = y_test.copy()\n",
    "y_train2 = y_train.copy()\n",
    "y_valid2 = y_valid.copy()\n",
    "\n",
    "y_test2[y_test2 >= 1] = 1\n",
    "y_train2[y_train2 >= 1] = 1\n",
    "y_valid2[y_valid2 >= 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lows = []\n",
    "best_his = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, wlo, whi = testModel(\"per\", X_train, y_train2, X_test, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5982480735244586"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lows.append(wlo)\n",
    "best_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.6300403395578715, 1),\n",
       " (0.6327767008305035, 10),\n",
       " (0.635323538477365, 100),\n",
       " (0.6306852761017345, 1000)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validscores = getScores(X_train, y_train2, X_valid, y_valid2, \"log\")\n",
    "validscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "i = getBestC(validscores)\n",
    "f1, wlo, whi = testModel(\"log\", X_train, y_train2, X_test, y_test2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6357892682397208"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lows.append(wlo)\n",
    "best_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.6499154309802414, 1),\n",
       " (0.6483635463952981, 10),\n",
       " (0.6375574193476646, 100),\n",
       " (0.5928681595346037, 1000)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validscores = getScores(X_train, y_train2, X_valid, y_valid2, \"svm\")\n",
    "validscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = getBestC(validscores)\n",
    "f1, wlo, whi = testModel(\"svm\", X_train, y_train2, X_test, y_test2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6502881649091025"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lows.append(wlo)\n",
    "best_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst vs Rest\n",
    "<a id=\"worst\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, the reviews were split into two classes. The first class is those reviews for books with an Amazon sales rank in the highest quartile, i.e. the least successful books, and the second class is all of the other books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test3 = y_test.copy()\n",
    "y_train3 = y_train.copy()\n",
    "y_valid3 = y_valid.copy()\n",
    "\n",
    "y_test3[y_test3 < 3] = 1\n",
    "y_train3[y_train3 < 3] = 1\n",
    "y_valid3[y_valid3 < 3] = 1\n",
    "\n",
    "y_test3[y_test3 == 3] = 0\n",
    "y_train3[y_train3 == 3] = 0\n",
    "y_valid3[y_valid3 == 3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_lows = []\n",
    "worst_his = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, wlo, whi = testModel(\"per\", X_train, y_train3, X_test, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8543770761017324"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_lows.append(wlo)\n",
    "worst_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8562188253029875, 1),\n",
       " (0.8622543037618972, 10),\n",
       " (0.8606296738277388, 100),\n",
       " (0.8599335127410591, 1000)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validscores = getScores(X_train, y_train3, X_valid, y_valid3, \"log\")\n",
    "validscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "i = getBestC(validscores)\n",
    "f1, wlo, whi = testModel(\"log\", X_train, y_train3, X_test, y_test3, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628591145077659"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_lows.append(wlo)\n",
    "worst_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8533848476665374, 1),\n",
       " (0.87187424331017, 10),\n",
       " (0.8714139451338925, 100),\n",
       " (0.8628777971973088, 1000)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validscores = getScores(X_train, y_train3, X_valid, y_valid3, \"svm\")\n",
    "validscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = getBestC(validscores)\n",
    "f1, wlo, whi = testModel(\"svm\", X_train, y_train3, X_test, y_test3, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8718262338499662"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_lows.append(wlo)\n",
    "worst_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Half vs Bottom Half\n",
    "<a id=\"fifty\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, the reviews were split into two classes. The first class is those reviews for books with an Amazon sales rank in the lowest two quartiles, i.e. the most successful books, and the second is those reviews for books in the highest two quartiles, i.e. the least successful books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test4 = y_test.copy()\n",
    "y_train4 = y_train.copy()\n",
    "y_valid4 = y_valid.copy()\n",
    "\n",
    "#good\n",
    "y_test4[y_test4 <= 1] = 0\n",
    "y_train4[y_train4 <= 1] = 0\n",
    "y_valid4[y_valid4 <= 1] = 0\n",
    "\n",
    "#bad\n",
    "y_test4[y_test4 > 1] = 1\n",
    "y_train4[y_train4 > 1] = 1\n",
    "y_valid4[y_valid4 > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifty_lows = []\n",
    "fifty_his = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, wlo, whi = testModel(\"per\", X_train, y_train4, X_test, y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6957016574554626"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifty_lows.append(wlo)\n",
    "fifty_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7172781176196038, 1),\n",
       " (0.7216132121812316, 10),\n",
       " (0.7145805948274276, 100),\n",
       " (0.7162239881505928, 1000)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validscores = getScores(X_train, y_train4, X_valid, y_valid4, \"log\")\n",
    "validscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "i = getBestC(validscores)\n",
    "f1, wlo, whi = testModel(\"log\", X_train, y_train4, X_test, y_test4, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7223545041033096"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifty_lows.append(wlo)\n",
    "fifty_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Svetha Pulavarty\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7391217132138415, 1),\n",
       " (0.7412991353772118, 10),\n",
       " (0.7374678267825139, 100),\n",
       " (0.7109205147457663, 1000)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validscores = getScores(X_train, y_train4, X_valid, y_valid4, \"svm\")\n",
    "validscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = getBestC(validscores)\n",
    "f1, wlo, whi = testModel(\"svm\", X_train, y_train4, X_test, y_test4, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426194456711266"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifty_lows.append(wlo)\n",
    "fifty_his.append(whi)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "<a id=\"res\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 0.25  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "width1 = np.arange(len(pscores))\n",
    "width2 = [x + width for x in width1]\n",
    "width3 = [x + width for x in width2]\n",
    "\n",
    "rects1 = ax.bar(width1, pscores, color='#7f6d5f', width=width, edgecolor='white', label='Perceptron')\n",
    "rects2 = ax.bar(width2, lscores, color='#557f2d', width=width, edgecolor='white', label='Logistic Regression')\n",
    "rects3 = ax.bar(width3, sscores, color='#2d7f5e', width=width, edgecolor='white', label='Linear SVM')\n",
    "\n",
    "plt.xlabel('Test', fontweight='bold')\n",
    "plt.xticks([r + width for r in width2], ['Multiclass', 'Best Books', 'Worst Books', \"Half-and-Half\"])\n",
    "\n",
    "ax.set_ylabel('F1 Scores')\n",
    "ax.set_title('F1 Scores by Algorithm and Test')\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(round(height,2)),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the Linear SVC model had the highest F1 scores, followed by the logistic regression model, followed by the perceptron. The predictors which took the least successful ebooks as a single class had the highest F1 scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Words for Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'matis': 2,\n",
       "         'shovelers': 2,\n",
       "         'lothair': 2,\n",
       "         'closeout': 2,\n",
       "         'chay': 1,\n",
       "         'granade': 1,\n",
       "         'padraig': 2,\n",
       "         'sonics': 2,\n",
       "         'payce': 2,\n",
       "         'rayce': 1,\n",
       "         'bitterthorn': 2,\n",
       "         'vonbrandt': 1,\n",
       "         'emlyn': 2,\n",
       "         '1918': 1,\n",
       "         'crawley': 1,\n",
       "         'hollins': 2,\n",
       "         'lunsford': 1,\n",
       "         'mirelle': 2,\n",
       "         'riann': 2,\n",
       "         'aynslee': 1,\n",
       "         'prudy': 1,\n",
       "         'ingro': 1,\n",
       "         'schiller': 1,\n",
       "         'kiden': 2,\n",
       "         'flury': 2,\n",
       "         'lantano': 1,\n",
       "         'barth': 2,\n",
       "         'suzannah': 2,\n",
       "         'rie': 2,\n",
       "         'dryad': 1,\n",
       "         'facts': 1,\n",
       "         'debut': 1,\n",
       "         'erik': 1,\n",
       "         'illustrations': 1,\n",
       "         'sydney': 1,\n",
       "         'green': 1,\n",
       "         'cynthia': 1,\n",
       "         'lane': 1,\n",
       "         'david': 1,\n",
       "         'sk': 1,\n",
       "         'foor': 1,\n",
       "         'cupid': 1,\n",
       "         'animals': 1,\n",
       "         'henry': 1,\n",
       "         'tips': 1,\n",
       "         'diet': 1,\n",
       "         'photos': 1,\n",
       "         'pictures': 1,\n",
       "         'laura': 1,\n",
       "         'sandra': 1,\n",
       "         'april': 1,\n",
       "         'guide': 1,\n",
       "         'strategies': 1,\n",
       "         'jay': 1,\n",
       "         'recipe': 1,\n",
       "         'austen': 1,\n",
       "         'rick': 1,\n",
       "         'dorian': 1,\n",
       "         'mike': 1,\n",
       "         'online': 1,\n",
       "         'mcfarlan': 1,\n",
       "         'appoint': 1,\n",
       "         'goofier': 1,\n",
       "         'dwi': 1,\n",
       "         'lingane': 1,\n",
       "         'neurons': 1,\n",
       "         'tenwick': 1,\n",
       "         'screened': 1,\n",
       "         '1640': 1,\n",
       "         'analysing': 1,\n",
       "         'croatia': 1,\n",
       "         'annica': 1,\n",
       "         'sibylla': 1})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x for xs in multi_lows for x in set(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sosie': 2,\n",
       "         'grimke': 1,\n",
       "         'lamanna': 1,\n",
       "         'iamwillow': 1,\n",
       "         'goldtree': 2,\n",
       "         'baltsaros': 1,\n",
       "         'gerritsen': 2,\n",
       "         'seligman': 2,\n",
       "         'meli': 1,\n",
       "         'beachwood': 2,\n",
       "         'pappano': 2,\n",
       "         'shandwick': 1,\n",
       "         'cardeno': 2,\n",
       "         'kawasaki': 2,\n",
       "         'cyprian': 2,\n",
       "         'shiftr': 1,\n",
       "         'tijan': 2,\n",
       "         'mechanica': 2,\n",
       "         'cowbear': 1,\n",
       "         'hamel': 2,\n",
       "         'subordination': 1,\n",
       "         'belvin': 2,\n",
       "         'sittenfeld': 2,\n",
       "         'kalanithi': 2,\n",
       "         'canterbary': 2,\n",
       "         'turano': 1,\n",
       "         'mackintosh': 2,\n",
       "         'aven': 1,\n",
       "         'stylo': 2,\n",
       "         'harrigan': 2,\n",
       "         'alexa': 1,\n",
       "         'terry': 1,\n",
       "         'jasinda': 1,\n",
       "         'zoe': 1,\n",
       "         'cayson': 1,\n",
       "         'caldwell': 1,\n",
       "         'lauren': 1,\n",
       "         'bolryder': 1,\n",
       "         'unlimited': 1,\n",
       "         'duke': 1,\n",
       "         'sloane': 1,\n",
       "         'rebel': 1,\n",
       "         'prequel': 1,\n",
       "         'ana': 1,\n",
       "         'dani': 1,\n",
       "         'jess': 1,\n",
       "         'hockey': 1,\n",
       "         'reacher': 1,\n",
       "         'kindred': 1,\n",
       "         'zane': 1,\n",
       "         'colton': 1,\n",
       "         'slade': 1,\n",
       "         'cal': 1,\n",
       "         'zeth': 1,\n",
       "         'buroker': 1,\n",
       "         'celia': 1,\n",
       "         'silver': 1,\n",
       "         'rylee': 1,\n",
       "         'ryker': 1,\n",
       "         'goins': 1,\n",
       "         'aniri': 1,\n",
       "         'maykayla': 1,\n",
       "         'lovegame': 1,\n",
       "         'robicheaux': 1,\n",
       "         'hotbod': 1,\n",
       "         'maili': 1,\n",
       "         'albanese': 1,\n",
       "         'desalls': 1,\n",
       "         'gaymers': 1,\n",
       "         'garris': 1,\n",
       "         'stelson': 1})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x for xs in multi_his for x in set(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Words for Best vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sosie': 2,\n",
       "         'hartnady': 1,\n",
       "         'goldtree': 1,\n",
       "         'baltsaros': 2,\n",
       "         'hetta': 3,\n",
       "         'goins': 2,\n",
       "         'beachwood': 2,\n",
       "         'pappano': 1,\n",
       "         'shandwick': 1,\n",
       "         'kawasaki': 2,\n",
       "         'shiftr': 2,\n",
       "         'tijan': 3,\n",
       "         'mechanica': 2,\n",
       "         'cowbear': 2,\n",
       "         'hamel': 3,\n",
       "         'lovegame': 1,\n",
       "         'belvin': 3,\n",
       "         'robicheaux': 1,\n",
       "         'sittenfeld': 2,\n",
       "         'kalanithi': 2,\n",
       "         'andriano': 1,\n",
       "         'kellington': 1,\n",
       "         'dornan': 1,\n",
       "         'mackintosh': 2,\n",
       "         'frenched': 1,\n",
       "         'ceony': 1,\n",
       "         'gansett': 1,\n",
       "         'aven': 2,\n",
       "         'stylo': 2,\n",
       "         'harrigan': 2,\n",
       "         'cayson': 1,\n",
       "         'jasinda': 1,\n",
       "         'caldwell': 1,\n",
       "         'nix': 1,\n",
       "         'bolryder': 1,\n",
       "         'scalzi': 1,\n",
       "         'aspen': 1,\n",
       "         'gentry': 1,\n",
       "         'oblivion': 1,\n",
       "         'baldacci': 1,\n",
       "         'thalia': 1,\n",
       "         'bradshaw': 1,\n",
       "         'iain': 1,\n",
       "         'andrei': 1,\n",
       "         'darrow': 2,\n",
       "         'reacher': 1,\n",
       "         'begley': 1,\n",
       "         'payton': 1,\n",
       "         'kindred': 1,\n",
       "         'rhett': 1,\n",
       "         'lucinda': 1,\n",
       "         'zeth': 2,\n",
       "         'azmir': 1,\n",
       "         'buroker': 2,\n",
       "         'rayna': 1,\n",
       "         'rylee': 1,\n",
       "         'wilding': 1,\n",
       "         'bodhi': 1,\n",
       "         'janny': 1,\n",
       "         'cardeno': 1,\n",
       "         'pucked': 1,\n",
       "         'mckinney': 1,\n",
       "         'keanu': 1,\n",
       "         'bene': 1,\n",
       "         'culloden': 1})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x for xs in best_lows for x in set(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'shovelers': 2,\n",
       "         'lothair': 1,\n",
       "         'burson': 1,\n",
       "         'granade': 2,\n",
       "         'camy': 1,\n",
       "         'sonics': 2,\n",
       "         'payce': 2,\n",
       "         'vonbrandt': 2,\n",
       "         'ferraro': 1,\n",
       "         '1918': 1,\n",
       "         'lingane': 1,\n",
       "         'crawley': 2,\n",
       "         'hollins': 1,\n",
       "         'rarities': 1,\n",
       "         'everglades': 1,\n",
       "         'riann': 2,\n",
       "         'aynslee': 1,\n",
       "         'analysing': 1,\n",
       "         'schiller': 1,\n",
       "         'kiden': 1,\n",
       "         'zabrinski': 2,\n",
       "         'shriver': 1,\n",
       "         'flury': 1,\n",
       "         'silber': 1,\n",
       "         'barth': 2,\n",
       "         'suzannah': 2,\n",
       "         'rie': 3,\n",
       "         'sibylla': 2,\n",
       "         'dryad': 1,\n",
       "         'duggan': 1,\n",
       "         'erik': 1,\n",
       "         'kasey': 1,\n",
       "         'jenika': 1,\n",
       "         'chay': 1,\n",
       "         'jani': 2,\n",
       "         'dorian': 1,\n",
       "         'tymber': 1,\n",
       "         'merrick': 1,\n",
       "         'den': 1,\n",
       "         'ivory': 1,\n",
       "         'bentley': 1,\n",
       "         'sk': 1,\n",
       "         'dickens': 1,\n",
       "         'saylor': 2,\n",
       "         'carla': 1,\n",
       "         'tiana': 1,\n",
       "         'cupid': 1,\n",
       "         'brielle': 1,\n",
       "         'tajana': 1,\n",
       "         'sandra': 1,\n",
       "         'tyce': 1,\n",
       "         'tania': 1,\n",
       "         'dix': 2,\n",
       "         'lorna': 1,\n",
       "         'magnolia': 1,\n",
       "         'daemon': 2,\n",
       "         'astrid': 1,\n",
       "         'ramsey': 1,\n",
       "         'foor': 1,\n",
       "         'pullo': 1,\n",
       "         'pembroke': 1,\n",
       "         'rayce': 1,\n",
       "         'didgeridoo': 1,\n",
       "         'bolling': 1,\n",
       "         'creighton': 1,\n",
       "         'gymnast': 1,\n",
       "         'rayanne': 1,\n",
       "         'aicher': 1,\n",
       "         'stiles': 1,\n",
       "         'aylee': 1,\n",
       "         'evy': 1,\n",
       "         'fawkes': 1,\n",
       "         'nikolaj': 1})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x for xs in best_his for x in set(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Words for Worst vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'mazzy': 1,\n",
       "         'hendin': 2,\n",
       "         'cowan': 2,\n",
       "         'viridis': 1,\n",
       "         'kucan': 1,\n",
       "         'burson': 2,\n",
       "         'zhoe': 1,\n",
       "         'scotto': 1,\n",
       "         'spina': 2,\n",
       "         'behiel': 1,\n",
       "         'devonwood': 2,\n",
       "         'forbearance': 1,\n",
       "         'pascale': 1,\n",
       "         'bellissimo': 1,\n",
       "         'kasonndra': 2,\n",
       "         'shortland': 1,\n",
       "         'nalia': 2,\n",
       "         'eror': 1,\n",
       "         'brennus': 1,\n",
       "         'annike': 1,\n",
       "         'presleigh': 1,\n",
       "         'flc': 1,\n",
       "         'pura': 1,\n",
       "         'vonn': 1,\n",
       "         'annica': 2,\n",
       "         'velden': 2,\n",
       "         'supay': 1,\n",
       "         'denniger': 1,\n",
       "         'arla': 2,\n",
       "         'khul': 1,\n",
       "         'homer': 1,\n",
       "         'dahlia': 1,\n",
       "         'brien': 1,\n",
       "         'und': 1,\n",
       "         'madame': 1,\n",
       "         'zeppi': 1,\n",
       "         'poppet': 1,\n",
       "         'moats': 1,\n",
       "         'burkholder': 1,\n",
       "         'nickie': 1,\n",
       "         'poems': 1,\n",
       "         'dickens': 1,\n",
       "         'kye': 1,\n",
       "         'cathy': 1,\n",
       "         'hills': 1,\n",
       "         'grisham': 1,\n",
       "         'wwe': 1,\n",
       "         'golf': 1,\n",
       "         'nicki': 1,\n",
       "         'laila': 1,\n",
       "         'quiz': 1,\n",
       "         'skai': 1,\n",
       "         'der': 1,\n",
       "         'satire': 1,\n",
       "         'darrin': 1,\n",
       "         'sary': 1,\n",
       "         'austen': 1,\n",
       "         'interactive': 1,\n",
       "         'gustavo': 1,\n",
       "         '1ns': 1,\n",
       "         'krebs': 1,\n",
       "         'northshore': 1,\n",
       "         'copperheart': 1,\n",
       "         'scuttlebuttreviews': 1,\n",
       "         'birchtree': 1,\n",
       "         'cannariato': 1,\n",
       "         'tage': 1,\n",
       "         'phalla': 1,\n",
       "         'delvino': 1,\n",
       "         'doco': 1,\n",
       "         'bressoff': 1,\n",
       "         'tachna': 1,\n",
       "         'stenhouse': 1,\n",
       "         'megamart': 1,\n",
       "         'adelita': 1,\n",
       "         'weighton': 1,\n",
       "         'leslea': 1,\n",
       "         'sagrario': 1,\n",
       "         'logician': 1,\n",
       "         'cantin': 1})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x for xs in worst_lows for x in set(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'mayer': 1,\n",
       "         'irrefutable': 1,\n",
       "         'heldt': 1,\n",
       "         'brax': 1,\n",
       "         'stallings': 1,\n",
       "         'sigal': 2,\n",
       "         'prentiss': 1,\n",
       "         'halston': 1,\n",
       "         'nietzsche': 2,\n",
       "         'bourbon': 1,\n",
       "         'b007k8qo28': 2,\n",
       "         'covington': 1,\n",
       "         'triller': 1,\n",
       "         'marquess': 1,\n",
       "         'marietta': 3,\n",
       "         'meeks': 1,\n",
       "         'mayans': 2,\n",
       "         'cragle': 1,\n",
       "         'westwood': 2,\n",
       "         'sittenfeld': 1,\n",
       "         'loren': 1,\n",
       "         'creeden': 1,\n",
       "         'oram': 1,\n",
       "         'wingate': 2,\n",
       "         'tule': 1,\n",
       "         'ronaldo': 1,\n",
       "         'foor': 1,\n",
       "         'hitz': 1,\n",
       "         'jasinda': 1,\n",
       "         'regnery': 2,\n",
       "         'reed': 1,\n",
       "         'saint': 1,\n",
       "         'lucian': 1,\n",
       "         'heath': 1,\n",
       "         'montana': 1,\n",
       "         'earl': 1,\n",
       "         'carrie': 1,\n",
       "         'duke': 1,\n",
       "         'tesla': 1,\n",
       "         'colt': 1,\n",
       "         'boxed': 1,\n",
       "         'regency': 1,\n",
       "         'hudson': 1,\n",
       "         'zoey': 1,\n",
       "         'brides': 1,\n",
       "         'bride': 1,\n",
       "         'series': 1,\n",
       "         'mail': 1,\n",
       "         'hockey': 1,\n",
       "         'seal': 1,\n",
       "         'mating': 1,\n",
       "         'reacher': 1,\n",
       "         'cozy': 1,\n",
       "         'mc': 1,\n",
       "         'ku': 1,\n",
       "         'reid': 1,\n",
       "         'billionaire': 1,\n",
       "         'darcy': 1,\n",
       "         'unlimited': 1,\n",
       "         'logos': 1,\n",
       "         'cataract': 1,\n",
       "         'beak': 1,\n",
       "         'pham': 1,\n",
       "         'gilstrap': 1,\n",
       "         'mobility': 1,\n",
       "         'kawasaki': 1,\n",
       "         'jamestown': 1,\n",
       "         'malediction': 1,\n",
       "         'snapper': 1,\n",
       "         'energize': 1,\n",
       "         'marcum': 1,\n",
       "         'pimple': 1,\n",
       "         'fenced': 1,\n",
       "         'kortni': 1,\n",
       "         'dade': 1,\n",
       "         'plath': 1,\n",
       "         'b00bh68rba': 1,\n",
       "         'voris': 1,\n",
       "         'oscars': 1,\n",
       "         'clopper': 1,\n",
       "         'wicka': 1})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x for xs in worst_his for x in set(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Words for Top Half vs Bottom Half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'katee': 2,\n",
       "         'heldt': 2,\n",
       "         'rothert': 1,\n",
       "         'gerritsen': 2,\n",
       "         'stallings': 1,\n",
       "         'taiden': 2,\n",
       "         'gonzalez': 2,\n",
       "         'provence': 2,\n",
       "         'goins': 2,\n",
       "         'marquita': 2,\n",
       "         'sonics': 1,\n",
       "         'aoleon': 2,\n",
       "         'moonbound': 1,\n",
       "         'killough': 1,\n",
       "         'cardeno': 1,\n",
       "         'kawasaki': 2,\n",
       "         'tijan': 2,\n",
       "         'sindia': 1,\n",
       "         'cartmell': 2,\n",
       "         'blucy': 1,\n",
       "         'burnham': 1,\n",
       "         'belvin': 1,\n",
       "         'darrow': 2,\n",
       "         'mackintosh': 1,\n",
       "         'carponti': 1,\n",
       "         'lemmon': 2,\n",
       "         'wingate': 2,\n",
       "         'forgy': 1,\n",
       "         'lebowski': 1,\n",
       "         'regnery': 2,\n",
       "         'noel': 1,\n",
       "         'jasinda': 1,\n",
       "         'lucian': 1,\n",
       "         'beck': 1,\n",
       "         'nix': 1,\n",
       "         'montana': 1,\n",
       "         'earl': 1,\n",
       "         'frost': 1,\n",
       "         'duke': 1,\n",
       "         'deborah': 1,\n",
       "         'vivienne': 1,\n",
       "         'sloane': 1,\n",
       "         'scalzi': 1,\n",
       "         'zoey': 1,\n",
       "         'brides': 1,\n",
       "         'aria': 1,\n",
       "         'hart': 1,\n",
       "         'marietta': 1,\n",
       "         'hockey': 1,\n",
       "         'reacher': 1,\n",
       "         'kindred': 1,\n",
       "         'colton': 1,\n",
       "         'neve': 1,\n",
       "         'zeth': 1,\n",
       "         'maddox': 1,\n",
       "         'buroker': 1,\n",
       "         'rylee': 1,\n",
       "         'unlimited': 1,\n",
       "         'levey': 1,\n",
       "         'wayland': 1,\n",
       "         'johanisburg': 1,\n",
       "         'neeny': 1,\n",
       "         'alcorn': 1,\n",
       "         'haeven': 1,\n",
       "         'b00gz5h6r4': 1,\n",
       "         'pimple': 1,\n",
       "         'aptos': 1,\n",
       "         'betrayers': 1,\n",
       "         'forneus': 1,\n",
       "         'voris': 1,\n",
       "         'sensuously': 1,\n",
       "         'marnee': 1,\n",
       "         'bouillon': 1,\n",
       "         'quidell': 1})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x for xs in fifty_lows for x in set(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'aliso': 2,\n",
       "         'kerstyn': 1,\n",
       "         'westervelt': 2,\n",
       "         'podger': 2,\n",
       "         'calinda': 1,\n",
       "         'warneke': 1,\n",
       "         'lingane': 2,\n",
       "         'foy': 1,\n",
       "         'ghiselle': 2,\n",
       "         'didgeridoo': 1,\n",
       "         'velasquez': 1,\n",
       "         'vieux': 1,\n",
       "         'somerton': 2,\n",
       "         'isthmus': 2,\n",
       "         'whitetail': 1,\n",
       "         'ingro': 2,\n",
       "         'ditter': 2,\n",
       "         'dreyer': 2,\n",
       "         'pura': 2,\n",
       "         'ceruleans': 1,\n",
       "         'lantano': 2,\n",
       "         'badewyn': 2,\n",
       "         'lashell': 1,\n",
       "         'marisela': 2,\n",
       "         'choisie': 1,\n",
       "         'sidda': 2,\n",
       "         'rawlyns': 2,\n",
       "         'brimble': 2,\n",
       "         'arla': 2,\n",
       "         'childstar': 1,\n",
       "         'debut': 1,\n",
       "         'lucca': 1,\n",
       "         'illustrations': 1,\n",
       "         'und': 1,\n",
       "         'spankings': 1,\n",
       "         'barron': 1,\n",
       "         'ricky': 1,\n",
       "         'jumpy': 1,\n",
       "         'coen': 1,\n",
       "         'tawny': 1,\n",
       "         'poems': 1,\n",
       "         'sk': 1,\n",
       "         'dickens': 1,\n",
       "         'ollie': 1,\n",
       "         'kye': 1,\n",
       "         'cupid': 1,\n",
       "         'poetry': 1,\n",
       "         'nala': 1,\n",
       "         'webb': 1,\n",
       "         'matilda': 1,\n",
       "         'betty': 1,\n",
       "         'bunker': 1,\n",
       "         'tania': 1,\n",
       "         'javier': 1,\n",
       "         'quiz': 1,\n",
       "         'der': 1,\n",
       "         'jolie': 1,\n",
       "         'austen': 1,\n",
       "         'procrastination': 1,\n",
       "         'investing': 1,\n",
       "         'mx': 1,\n",
       "         'hendin': 1,\n",
       "         'nuss': 1,\n",
       "         'mcbryde': 1,\n",
       "         'westfall': 1,\n",
       "         'angelisa': 1,\n",
       "         'hollins': 1,\n",
       "         'kaston': 1,\n",
       "         'brison': 1,\n",
       "         'kiden': 1,\n",
       "         'adgate': 1,\n",
       "         'deveaux': 1})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x for xs in fifty_his for x in set(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "<a id=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting whether a book is in the least successful quartile for Amazon sales rankings seems to be much easier than predicting whether an ebook is in the most successful quartile. This may be because an ebooks success relies on luck in addition to quality, and by quality alone, it may be possible to only easily predict the least successful with a high degree of accuracy. It might also be because the boundary between the least successful quartile and the rest of the ebooks is more defined than other boundaries. \n",
    "\n",
    "The multiclass algorithms, in contrast, did the worst, in part because the classes were attempting to make four discrete segments from a continuous scale. Determining whether an ebook was in the most successful quartile was also less successful, possibly because the difference between a highly successful ebook and an ebook of middling success is more negligible. For a similar reason, predicting whether an ebook was in the top 50% or lowest 50% was also less successful. \n",
    "\n",
    "The models were chosen for their interpretability. However, many of the lowest and highest weighted words seem to be names rather than more meaningful words. Famous authors such as Dickens and Austen seem to appear more in reviews for more successful books, as are words such as poetry and illustrations. Interestingly, words correlated with lower Amazon sales rankings include Regency, unlimited, and series. This suggests works in a series may be more likely to have lower rankings, as are books from the Regency romance genre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "<a id=\"concl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall it seems likely that a single review can predict whether or not an ebook will be in the lowest quartile of sales rankings in the Amazon Kindle store. It would be interesting to use a linear regression model to predict the actual sales ranking from a review, in contrast to the multiclass models, which created four discrete classes from a continuous scale. \n",
    "\n",
    "While the models were interpretable, bias might exist. The lowest quartile of sales rankings, given the logistic regression model, was correlated with terms such as Regency, which are in turn related to the female-led romance genre. There is therefore a possibility of bias in that female-written works might be ranked lower than male-written works. Additionally, since famous authors are correlated with better rankings, this algorithm might overlook authors with less fame who are just as talented. \n",
    "\n",
    "Further research is necessary to reduce bias in the models and to create a classifier that might better predict sales rankings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "<a id=\"citations\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cit1\"></a>[1]\tK. Kousha, M. Thelwall, and S. Rezaie, Assessing the citation impact of books: The role of Google Books, Google Scholar, and Scopus, J. Am. Soc. Inf. Sci. Technol., vol. 62, no. 11, pp. 21472164, 2011, doi: 10.1002/asi.21608.  \n",
    "\n",
    "<a id=\"cit2\"></a>[2]\tA. A. Zuccala, F. T. Verleysen, R. Cornacchia, and T. C. E. Engels, Altmetrics for the humanities: Comparing Goodreads reader ratings with citations to history books, Aslib J. Inf. Manag., vol. 67, no. 3, pp. 320336, Jan. 2015, doi: 10.1108/AJIM-11-2014-0152.\n",
    "\n",
    "<a id=\"cit3\"></a>[3]\tK. Kousha and M. Thelwall, Can Amazon.com reviews help to assess the wider impacts of books?, J. Assoc. Inf. Sci. Technol., vol. 67, no. 3, pp. 566581, Mar. 2016, doi: 10.1002/asi.23404.\n",
    "\n",
    "<a id=\"cit4\"></a>[4]\tQ. Zhou, C. Zhang, S. X. Zhao, and B. Chen, Measuring book impact based on the multi-granularity online review mining, Scientometrics, vol. 107, no. 3, pp. 14351455, Jun. 2016, doi: 10.1007/s11192-016-1930-5.\n",
    "\n",
    "<a id=\"cit5\"></a>[5]\tJ. A. Chevalier and D. Mayzlin, The Effect of Word of Mouth on Sales: Online Book Reviews:, J. Mark. Res., Oct. 2018, doi: 10.1509/jmkr.43.3.345.\n",
    "\n",
    "<a id=\"cit6\"></a>[6]\tAmazon review data. https://nijianmo.github.io/amazon/index.html#subsets (accessed Apr. 29, 2020)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
